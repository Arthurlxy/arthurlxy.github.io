---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

# About Me
I am an applied scientist at [Amazon AI (Rekognition)](https://aws.amazon.com/rekognition/).
My research interests are video understanding (including action recognition, action detection, action segmentation, etc.) and multimedia understanding (including sound classification, the multimodality fusion, emotion recognition, etc.). I am also actively contributing to open-source tools [GluonCV](https://cv.gluon.ai/).

Before joining Amazon, I received my Ph.D. Degree (2018) at [Rutgers University](https://www.rutgers.edu/) supervised by Prof. [Ivan Marsic](https://www.ece.rutgers.edu/~marsic/).
I received my Bachelorâ€™s Degree (2013) at [UniversiUniversity of Electronic Science and Technology of China](https://www.uestc.edu.cn/).


# News
* [**2021**] **NeurIPS 2021 (Spotlight)** "Long Short-Term Transformer for Online Action Detection". [Paper](https://arxiv.org/abs/2107.03377)
* [**2021**] GluonMM is now available [Link](https://github.com/amazon-research/gluonmm)
* [**2021**] **ICCV 2021** publication: "VidTr: Video Transformer Without Convolutions". [Paper](https://arxiv.org/abs/2104.11746)
* [**2021**] **ICCV 2021** publication: "Selective Feature Compression for Efficient Activity Recognition Inference". [Paper](https://arxiv.org/pdf/2104.00179.pdf)
* [**2021**] **CVPR 2021** publication: "Multi-Label Activity Recognition using Activity-specific Features and Activity Correlations". [Paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Multi-Label_Activity_Recognition_Using_Activity-Specific_Features_and_Activity_Correlations_CVPR_2021_paper.pdf)
* [**2021**] **CVPR 2021** publication: "SiamMOT: Siamese Multi-Object Tracking". [Paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Shuai_SiamMOT_Siamese_Multi-Object_Tracking_CVPR_2021_paper.pdf)
* [2020] Check out our work on action recognition: "NUTA: Non-uniform Temporal Aggregation for Action Recognition". [Paper](https://arxiv.org/pdf/2012.08041.pdf)
* [2020] The **Gluon Toolkit** with pytorch support is now available! [GluonCV](https://cv.gluon.ai/).
* [2020] Survey paper "A Comprehensive Study of Deep Video Action Recognition" is available: [Paper](https://arxiv.org/abs/2012.06567).
* [2020] **ECCV 2020 (Spotlight)** Publication: "Directional temporal modeling for action recognition". [Paper](https://assets.amazon.science/67/d7/e6b2da584d57b6928b652fc75fa1/directional-temporal-modeling-for-action-recognition.pdf).
* [2020] **3rd place** in ACM MM HIE challange. [Paper](https://dl.acm.org/doi/abs/10.1145/3394171.3416297)
* [2019] **ACM MM 2019** puvlication: "Mutual correlation attentive factors in dyadic fusion networks for speech emotion recognition". [Paper](https://dl.acm.org/doi/abs/10.1145/3343031.3351039)
* [2019] **InterSpeech 2019** publication: "Speech Audio Super-Resolution for Speech Recognition". [Paper](https://www.isca-speech.org/archive/Interspeech_2019/pdfs/3043.pdf)
* [2019] **InterSpeech 2019** publication: "Multi-stream network with temporal attention for environmental sound classification". [Paper](https://www.isca-speech.org/archive/Interspeech_2019/pdfs/3019.pdf)
